<!DOCTYPE html><html lang=fr><head><meta charset=utf-8 /><meta content="width=device-width,initial-scale=1" name=viewport /><title>Ruby : web scraping avec la gem Nokogiri &bull; Antoine Brisset</title><meta content="Ruby possède de sompteuses Gems pour le scraping de contenu. Voici une présentation de la Gem Nokogiri avec un exemple concret de scraping SEO." name=description /><meta content="index,follow" name=robots /><meta content=R7aPiADkUTnBNzbTvsqutfN3_gewIxUFwJpKYyc-hBQ name=google-site-verification /><link href="/apple-touch-icon.png" rel=apple-touch-icon sizes=57x57 /><link href="/apple-touch-icon-57x57-precomposed.png" rel=apple-touch-icon sizes=57x57 /><link href="/apple-touch-icon-60x60-precomposed.png" rel=apple-touch-icon sizes=60x60 /><link href="/apple-touch-icon-72x72-precomposed.png" rel=apple-touch-icon sizes=72x72 /><link href="/apple-touch-icon-76x76-precomposed.png" rel=apple-touch-icon sizes=76x76 /><link href="/apple-touch-icon-114x114-precomposed.png" rel=apple-touch-icon sizes=114x114 /><link href="/apple-touch-icon-120x120-precomposed.png" rel=apple-touch-icon sizes=120x120 /><link href="/apple-touch-icon-144x144-precomposed.png" rel=apple-touch-icon sizes=144x144 /><link href="/apple-touch-icon-152x152-precomposed.png" rel=apple-touch-icon sizes=152x152 /><link href="/favicon-196x196.png" rel=icon sizes=196x196 type="image/png"/><link href="/favicon-160x160.png" rel=icon sizes=160x160 type="image/png"/><link href="/favicon-96x96.png" rel=icon sizes=96x96 type="image/png"/><link href="/favicon-32x32.png" rel=icon sizes=32x32 type="image/png"/><link href="/favicon-16x16.png" rel=icon sizes=16x16 type="image/png"/><meta content="#f5f5f5" name=msapplication-TileColor /><meta content="/mstile-144x144.png" name=msapplication-TileImage /><link href="/stylesheets/application.css" rel=stylesheet /><link href="//fonts.googleapis.com/css?family=Open+Sans:400,300,600,700,800" rel=stylesheet /><link href="//maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css" rel=stylesheet /><style>.header{background-image: url('/images/backgrounds/small/code.jpeg');}
    @media screen and (min-width: 25em){.header{background-image: url('/images/backgrounds/medium/code.jpeg');}}
    @media screen and (min-width: 50em){.header{background-image: url('/images/backgrounds/code.jpeg');}}</style><script src="/javascripts/all.js"></script></head><body class="blog blog_ruby-scraping blog_ruby-scraping_index"> <noscript><iframe src="//www.googletagmanager.com/ns.html?id=GTM-WW7MSH" height=0 width=0 style="display:none;visibility:hidden"></iframe></noscript> <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
          new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
          j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
          '//www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
          })(window,document,'script','dataLayer','GTM-NKG6T7');</script> <div class=wrapper><nav role=navigation><div class=fat-nav><div class=fat-nav__wrapper><ul><li><a href="/">Accueil</a></li><li><a href="/blog/">Blog SEO</a></li><li><a href="/#contact">Contact</a></li></ul></div></div></nav></div><div role=main></div><div class=header><div class=wrapper><h1 class=header__title>Scraper facilement avec Ruby et Nokogiri</h1><p class=header__category><i class="fa fa-tag"></i> <em>Scripts SEO</em></p></div></div><div class="section section__content--large"><div class=wrapper><article class=blog__article><p class=blog__breadcrumb><a href="/blog/">Blog SEO</a> / <a href="/blog/categories/scripts-seo/">Scripts SEO</a></p><p class=blog__date>Publié le 15 Apr 2013</p><p class=blog__chapo>Le scraping est l'une des actions qui fait partie du quotidien d'un SEO. On peut s'en servir par exemple en phase d'audit pour extraire le contenu de certaines balises, en phase de netlinking pour extraire les résultats Google, etc. Je vais vous présenter ici un petit script ruby réalisé avec l'aide de <a href='https://twitter.com/__clement___'>@clement_</a>, et qui vous sera peut-être utile si vous n'avez pas sous la main un logiciel approprié. Vous pourrez l'exécuter directement en console et récupérer ainsi rapidement ce dont vous avez besoin.</p><h2>1ère étape : récupérer uniquement les données utiles du CSV</h2> <p>Tout d&#39;abord, nous devons installer la gem &ldquo;nokogiri&rdquo; qui permet de parser et de scraper des documents en s&#39;appuyant sur des sélecteurs CSS ou des expressions XPath. Nous avons également besoin de la librairie &ldquo;open-uri&rdquo; et de la libraire &ldquo;CSV&rdquo;, qui sont toutes deux des librairies standards de ruby.</p> <div class=highlight><pre class="highlight ruby"><code><span class="c1">#!/usr/bin/ruby</span>

<span class="nb">require</span> <span class="s1">'rubygems'</span>
<span class="nb">require</span> <span class="s1">'nokogiri'</span>
<span class="nb">require</span> <span class="s1">'open-uri'</span>
<span class="nb">require</span> <span class="s1">'CSV'</span>
</code></pre></div> <p>Nous récupérons dans un premier temps le contenu du CSV dans un array à l&#39;aide de la classe CSV et de la méthode read, en spécifiant le chemin du fichier ainsi que le délimiteur utilisé, par exemple ici le point virgule.</p> <div class=highlight><pre class="highlight ruby"><code><span class="n">array_of_arrays</span> <span class="o">=</span> <span class="no">CSV</span><span class="p">.</span><span class="nf">read</span><span class="p">(</span><span class="s2">"./urls.csv"</span><span class="p">,</span> <span class="p">{</span><span class="ss">col_sep: </span><span class="s2">";"</span><span class="p">})</span>
</code></pre></div> <p>Il faut ensuite écrire la méthode qui permet de ne récupérer que le premier élément de chaque array de l&#39;array global récupéré précédemment. Autrement dit, uniquement la première cellule de chaque ligne de notre CSV si notre CSV comporte plusieurs colonnes.</p> <p>Pour cela, nous utilisons la méthode reduce. La méthode reduce permet, à partir d&#39;un array, de retourner une valeur unique ou un array. Nous allons dans un premier temps &ldquo;passer&rdquo; à reduce un tableau vide en valeur initiale ([]). Puis initier la boucle.</p> <div class=highlight><pre class="highlight ruby"><code><span class="n">array</span><span class="p">.</span><span class="nf">reduce</span><span class="p">([])</span> <span class="k">do</span> <span class="o">|</span><span class="n">result</span><span class="p">,</span> <span class="n">elem</span><span class="o">|</span>
</code></pre></div> <p>A chaque passe, donc sur chaque élément de l&#39;array (elem), la valeur totale est incrémentée (result). Maintenant que nous avons découpé notre array, il ne reste plus qu&#39;à demander à ruby de stocker dans &ldquo;result&rdquo; la première valeur de chaque &ldquo;elem&rdquo;, c&#39;est-à-dire la première cellule de chaque ligne du fichier de base.</p> <div class=highlight><pre class="highlight ruby"><code><span class="n">result</span> <span class="o">&lt;&lt;</span> <span class="n">elem</span><span class="p">.</span><span class="nf">first</span>
</code></pre></div> <p>Ce qui donne :</p> <div class=highlight><pre class="highlight ruby"><code><span class="k">def</span> <span class="nf">select_first_array_elem</span><span class="p">(</span><span class="n">array</span><span class="p">)</span>
<span class="err"> </span> <span class="n">array</span><span class="p">.</span><span class="nf">reduce</span><span class="p">([])</span> <span class="k">do</span> <span class="o">|</span><span class="n">result</span><span class="p">,</span> <span class="n">elem</span><span class="o">|</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">result</span> <span class="o">&lt;&lt;</span> <span class="n">elem</span><span class="p">.</span><span class="nf">first</span>
<span class="err"> </span> <span class="k">end</span>
<span class="k">end</span>
</code></pre></div> <h2>2ème étape : scraper sur la liste d&#39;URLs</h2> <p>Il faut ensuite définir la méthode qui permet de récupérer les données recherchées dans le document HTML. C&#39;est là qu&#39;entre en scène <a href="http://nokogiri.org/">Nokogiri</a>. Dans un premier temps, nous allons récupérer le contenu du document dans une variable.</p> <div class=highlight><pre class="highlight ruby"><code><span class="k">def</span> <span class="nf">analyse_url</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
  <span class="n">data</span> <span class="o">=</span> <span class="no">Nokogiri</span><span class="o">::</span><span class="no">HTML</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="n">url</span><span class="p">))</span>
</code></pre></div> <p>Puis à partir de cette variable, récupérer le contenu du noeud qui nous intéresse. Par exemple, la balise title.</p> <div class=highlight><pre class="highlight ruby"><code><span class="n">title</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="nf">xpath</span><span class="p">(</span><span class="s2">"//title"</span><span class="p">).</span><span class="nf">text</span>
</code></pre></div> <p>Et enfin, retourner le résultat. Ce qui donne donc :</p> <div class=highlight><pre class="highlight ruby"><code><span class="k">def</span> <span class="nf">analyse_url</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
  <span class="n">data</span>  <span class="o">=</span> <span class="no">Nokogiri</span><span class="o">::</span><span class="no">HTML</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="n">url</span><span class="p">))</span>
  <span class="n">title</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="nf">xpath</span><span class="p">(</span><span class="s2">"//title"</span><span class="p">).</span><span class="nf">text</span>
  <span class="n">title</span>
<span class="k">end</span>
</code></pre></div> <h2>3ème étape : boucler sur chaque url</h2> <p>Une fois la méthode de scrape définie, il faut définir la méthode qui permet de boucler sur chaque élément de l&#39;array obtenu en 1. Nous déclarons une variable &ldquo;result&rdquo;, avec array vide. Puis nous lançons la boucle (.each do). Chaque élément &ldquo;url&rdquo; de la boucle devient un argument de la fonction de scrape précédente et l&#39;ensemble est stocké dans &ldquo;result&rdquo;.</p> <div class=highlight><pre class="highlight ruby"><code><span class="k">def</span> <span class="nf">scraping_each_url</span><span class="p">(</span><span class="n">array</span><span class="p">)</span>
  <span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">array</span><span class="p">.</span><span class="nf">each</span> <span class="k">do</span> <span class="o">|</span><span class="n">url</span><span class="o">|</span>
    <span class="n">result</span> <span class="o">&lt;&lt;</span> <span class="n">analyse_url</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
  <span class="k">end</span>
  <span class="n">result</span>
<span class="k">end</span>
</code></pre></div> <h2>Dernière étape : afficher les données récupérées</h2> <p>Il ne reste plus qu&#39;à afficher les données pour chaque url. Pour cela rien de plus simple.On apelle les méthodes que l&#39;on a définies.</p> <div class=highlight><pre class="highlight ruby"><code><span class="n">array1</span>  <span class="o">=</span> <span class="n">select_first_array_elem</span><span class="p">(</span><span class="n">array_of_arrays</span><span class="p">)</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">scraping_each_url</span><span class="p">(</span><span class="n">array1</span><span class="p">)</span>
</code></pre></div> <p>Puis on affiche le résultat en console.</p> <div class=highlight><pre class="highlight ruby"><code><span class="nb">puts</span> <span class="s2">"</span><span class="si">#{</span><span class="n">results</span><span class="si">}</span><span class="s2">"</span>
</code></pre></div> <p>Bien entendu, l&#39;idéal est d&#39;enregistrer le résultat dans un nouveau fichier CSV en sortie.Là non plus rien de sorcier et je vous laisse vous reporter à la <a href="http://ruby-doc.org/stdlib-1.9.2/libdoc/csv/rdoc/CSV.html#label-Writing">doc ruby</a> pour finir le travail ;)</p> <div id=disqus_thread></div> <script>
//<![CDATA[
                  var disqus_shortname = 'blogantoinebrisset';
          
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
//]]>
</script> <noscript>Please enable JavaScript to view the <a href='http://disqus.com/?ref_noscript'>comments powered by Disqus.</a></noscript> <a href='http://disqus.com' class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a> </article></div></div><footer class=footer><div role=content-info><ul class=footer__content><li class=footer__content__item><i class="fa fa-home"></i> Marquette-lez-Lille</li><li class=footer__content__item><i class="fa fa-phone"></i> 06 12 71 82 78</li><li class=footer__content__item><i class="fa fa-envelope"></i> <a href="#email-protection-pbagnpg@nagbvar-oevffrg.pbz">contact@antoine-brisset.com</a> </li></ul><ul class=footer__content--social><li class=footer__content__item--social><a href="https://twitter.com/abrisset"><i class='fa fa-twitter footer__icon'></i></a></li><li class=footer__content__item--social><a href="https://github.com/ABrisset"><i class='fa fa-github footer__icon'></i></a></li><li class=footer__content__item--social><a href="http://plus.google.com/112811217796192792405?rel=author"><i class='fa fa-google-plus footer__icon'></i></a></li></ul><div class=footer__copyright> &copy; 2019 - <a href="/">Antoine Brisset</a></div></div></footer><script type="text/javascript">!function(){try{var a,b,c,d,g=document.getElementsByTagName("a");for(c=0;g.length-c;c++)try{b=g[c].getAttribute("href"),b&&b.indexOf("#email-protection-")>-1&&b.length>19&&(a="",d=19+b.indexOf("#email-protection-"),b.length>d&&(a=b.substr(18).replace(/[a-zA-Z]/g,function(a){return String.fromCharCode(("Z">=a?90:122)>=(a=a.charCodeAt(0)+13)?a:a-26)})),g[c].setAttribute("href","mailto:"+a))}catch(h){}}catch(h){}}();</script>
</body></html>